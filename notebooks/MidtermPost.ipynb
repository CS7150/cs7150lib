{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to setup visualization...\n",
    "# This cell defines plot_progress() which plots an optimization trace.\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_progress(bowl, track, losses):\n",
    "    # Draw the contours of the objective function, and x, and y\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 5))\n",
    "    for size in torch.linspace(0.1, 1.0, 10):\n",
    "        angle = torch.linspace(0, 6.3, 100)\n",
    "        circle = torch.stack([angle.sin(), angle.cos()])\n",
    "        ellipse = torch.mm(torch.inverse(bowl), circle) * size\n",
    "        ax1.plot(ellipse[0,:], ellipse[1,:], color='skyblue')\n",
    "    track = torch.stack(track).t()\n",
    "    ax1.set_title('progress of x')\n",
    "    ax1.plot(track[0,:], track[1,:], marker='o', markersize=3, linewidth=0.5)\n",
    "    ax1.set_ylim(-1, 1)\n",
    "    ax1.set_xlim(-1.6, 1.6)\n",
    "    ax1.set_ylabel('x[1]')\n",
    "    ax1.set_xlabel('x[0]')\n",
    "    ax2.set_title('progress of y')\n",
    "    ax2.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    ax2.plot(range(len(losses)), losses, marker='o')\n",
    "    ax2.set_ylabel('objective')\n",
    "    ax2.set_xlabel('iteration')\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "import torch, os, PIL.Image, numpy\n",
    "from matplotlib import cm\n",
    "from baukit import show\n",
    "\n",
    "def rgb_heatmap(data, size=None, colormap='hot', amax=None, amin=None, mode='bicubic', symmetric=False):\n",
    "    size = spec_size(size)\n",
    "    mapping = getattr(cm, colormap)\n",
    "    scaled = torch.nn.functional.interpolate(data[None, None], size=size, mode=mode)[0,0]\n",
    "    if amax is None: amax = data.max()\n",
    "    if amin is None: amin = data.min()\n",
    "    if symmetric:\n",
    "        amax = max(amax, -amin)\n",
    "        amin = min(amin, -amax)\n",
    "    normed = ((scaled - amin) / (amax - amin + 1e-10)).numpy()\n",
    "    return PIL.Image.fromarray((255 * mapping(normed)).astype('uint8'))\n",
    "\n",
    "def spec_size(size):\n",
    "    if isinstance(size, int): dims = (size, size)\n",
    "    if isinstance(size, torch.Tensor): size = size.shape[:2]\n",
    "    if isinstance(size, PIL.Image.Image): size = (size.size[1], size.size[0])\n",
    "    if size is None: size = (224, 224)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate vs Loss on Pytorch Optimizers\n",
    "\n",
    "Here is regular gradient descent with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_init = torch.tensor([1.0, 1.1])\n",
    "x = x_init.clone()\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.SGD([x], lr=0.1, momentum=0.5)\n",
    "\n",
    "bowl = torch.tensor([[ 0.4410, -1.0317], [-0.2844, -0.1035]])\n",
    "track, losses = [], []\n",
    "\n",
    "for iter in range(21):\n",
    "    loss = torch.mm(bowl, x[:,None]).norm()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    track.append(x.detach().clone())\n",
    "    losses.append(loss.detach())\n",
    "    \n",
    "plot_progress(bowl, track, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.\n",
    "\n",
    "Copy the code above twice, below, and then modify it in three ways:\n",
    "    \n",
    "(1) In one copy, decrease the learning rate by 10x  (i.e., 0.01)\n",
    "(2) In the other copy, multiplly the loss by 1/10 (i.e., * 0.1).  Compare the results.\n",
    "(3) Now try with and without momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with Adam\n",
    "----------------------\n",
    "\n",
    "Here is Adam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below uses Adam\n",
    "x = x_init.clone()\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "track, losses = [], []\n",
    "\n",
    "for iter in range(21):\n",
    "    loss = torch.mm(bowl, x[:,None]).norm()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    track.append(x.detach().clone())\n",
    "    losses.append(loss.detach())\n",
    "    \n",
    "plot_progress(bowl, track, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.\n",
    "\n",
    "Now copy the Adam code below, but decrease the loss by 1000x (e.g., multiply by 0.001).  What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy the and modify the Adam code below, decreasing loss by 1000x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions by hand: the networks is a picture of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://cs7150.baulab.info/2022-Fall/data/midterm_2d_conv_data.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv = torch.nn.Conv2d(\n",
    "        in_channels  = 1,\n",
    "        out_channels = 1,\n",
    "        kernel_size  = (5,5),\n",
    "        padding      = 2)\n",
    "\n",
    "    conv.weight[:,:,:,:] = torch.tensor([[[\n",
    "\n",
    "        [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "\n",
    "        [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "\n",
    "        [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "\n",
    "        [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "\n",
    "        [-1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "\n",
    "    ]]])\n",
    "    conv.bias[:] = torch.tensor(\n",
    "\n",
    "        [-1.0]\n",
    "\n",
    "    )\n",
    "\n",
    "    class Sign(torch.nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.sign()\n",
    "\n",
    "    net = torch.nn.Sequential(\n",
    "        conv,\n",
    "        Sign()\n",
    "    )\n",
    "\n",
    "    input_data = torch.load('midterm_2d_conv_data.pt')\n",
    "    output = net(input_data)\n",
    "\n",
    "    show([[\n",
    "        show.style(width=300), rgb_heatmap(input_data[0,0], 800, mode='nearest', symmetric=True),\n",
    "        show.style(width=300), rgb_heatmap(output[0,0], 800, mode='nearest', symmetric=True),\n",
    "        show.style(width=300), rgb_heatmap((output+input_data)[0,0], 800, mode='nearest', symmetric=True),\n",
    "    ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running out of memory\n",
    "\n",
    "Try and fix the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # Don't run this by default - remove this line to try this cell.\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "# commented out: # torch.set_grad_enabled(False)\n",
    "num_pixels = 1000000\n",
    "bottleneck = 100\n",
    "net = Sequential(\n",
    "    Linear(in_features=num_pixels, out_features=bottleneck, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(in_features=bottleneck, out_features=num_pixels, bias=False)\n",
    ").cuda()\n",
    "print('Parameter tensors', len(list(net.named_parameters())))\n",
    "print('Parameter elements', sum(p.numel() for p in net.parameters()))\n",
    "total_error = 0\n",
    "sample_size = 10000\n",
    "for test_index in range(sample_size):\n",
    "    test_data = torch.randn(1, num_pixels, device='cuda')\n",
    "    total_error += (net(test_data) - test_data).pow(2).mean()\n",
    "print('Average error', total_error / sample_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
